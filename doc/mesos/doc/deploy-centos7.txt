mesos 部署

参考文档

使用 Docker， 7 个命令部署一个 Mesos 集群
https://segmentfault.com/a/1190000002531072
Docker的save和export命令的区别
https://www.linuxidc.com/Linux/2014-04/100631.htm
使用Docker 部署Mesos集群
https://github.com/sekka1/mesosphere-docker#multi-node-setup

安装docker
yum install docker-io

启动docker服务：
service docker start

导出容器
docker export <CONTAINER ID> > /home/export.tar

导入容器
cat /home/export.tar | sudo docker import - busybox-1-export:latest

保存镜像
docker save <IMAGE NAME> > /home/save.tar

装载镜像
docker load < /home/save.tar

查看镜像
docker images

显示镜像的所有层(layer)
docker images --tree

层回滚
docker tag <LAYER ID> <IMAGE NAME>

运行镜像
docker run

启动容器
docker start

echo `date`-"hello mesos" >> /tmp/output.txt

登入docker
docker exec -it mesos_slave_1 /bin/bash

Trouble Shooting ====================================
1-----------------------
garland/mesosphere-docker-mesos-master
Exited (139)
似乎是命令行参数${HOST_IP}没有正确转换，确认环境参数已设置并已生效，
再次执行docker 启动命令即可正常执行。
2-----------------------
/etc/profile 修改配置后没有立即生效
需要执行(注意不能加sudo )
source /etc/profile 或 . /etc/profile
3-----------------------
执行docker 报错
docker: Cannot connect to the Docker daemon. Is the docker daemon running on this host?.
需要添加sudo 执行。
4-----------------------
Mesos 单节点集群，增加一个Slave 节点后，资源被正常统计但该节点状态始终显示Deactivated
https://yeasy.gitbooks.io/docker_practice/content/advanced_network/bridge.html
配置修改网桥docker0
sudo yum install bridge-utils
sudo service docker stop
ip addr del 172.17.0.1/16 dev docker0
ip addr replace 172.17.0.2/16 dev docker0
ip link set dev docker0 down
brctl addbr bridge0
ip addr add 172.28.32.182/24 dev bridge0
ip link set dev bridge0 up
echo 'DOCKER_OPTS="-b=bridge0"' >> /etc/default/docker
5-----------------------
https://segmentfault.com/a/1190000002531072
按照文档中介绍可以正常部署，然后在另一台虚拟主机中增加一个节点部署为mesos slave，
但新增的mesos slave在mesos控制台上只能看到cpu和磁盘资源的增加但是slaves的状态始终是Deactivated；
并且master控制台中认为slave与master在同一台主机ip下。
在mesos master中进行测试：
master宿主主机ip为172.28.109.240
master docker ip为172.17.0.1/16
slave宿主主机ip为172.28.110.57
slave docker ip为172.17.0.2/16
在master docker中只能ping通172.28.110.57，也可以ping通172.17.0.2
但在master docker中通过端口连接只能联通172.28.110.57，无法连通172.17.0.2？
解决办法：
之所以能够ping通172.17.0.2，是因为两台机器各自有一个172.17.0.0/16的局域网，
并各有一个ip为172.17.0.2的docker
修改172.28.110.57的docker0
vi /usr/lib/systemd/system/docker.service
ExecStart=/bin/sh -c '/usr/bin/docker-current daemon \
------------
          --bip=172.18.42.1/16 \
------------
          --exec-opt native.cgroupdriver=systemd \

systemctl daemon-reload
systemctl stop docker
systemctl start docker
在172.28.109.240修改
# route add -net 172.18.0.0/16 gw 172.28.110.57
# centos 7
ip route add 172.18.0.0/16 via 172.28.110.57
在172.28.110.57修改
# route add -net 172.17.0.0/16 gw 172.28.109.240
ip route add 172.17.0.0/16 via 172.28.109.240
查看路由表
ip route list
ip route show
查看资料可能还有其他方式？
通过传ip参数，设置slave宿主机ip，
master通过宿主机ip和端口映射（5051？）访问slave？

部署docker 集群
curl -X POST -H "Accept: application/json" -H "Content-Type: application/json" \
localhost:8080/v2/apps -d '{
"container": {
    "docker": {"image": "vmware/harbor-ui"},
    "type": "MESOS"
},
"cpus": 0.5,
"cmd": "sleep 500",
"id": "harbor-log",
"instances": 1,
"mem": 300
}'

curl -X PUT -H "Content-Type: application/json" localhost:8080/v2/apps/docker-tester \
"container": {"image": "docker:///libmesos/ubuntu", "options": ["--privileged"]},
"cpus": 0.5,
"cmd": "sleep 500",
"id": "docker-tester",
"instances": 2, # increasing the instance count to 2
"mem": 300
}'

```
vi nginx.json

{
  "id":"nginx",
  "cpus":0.2,
  "mem":20.0,
 "instances": 1,
 "constraints": [["hostname", "UNIQUE",""]],
 "container": {
    "type":"DOCKER",
   "docker": {
     "image": "nginx",
     "network": "BRIDGE",
     "portMappings": [
        {"containerPort": 8888, "hostPort": 0,"servicePort": 0, "protocol": "tcp" }
      ]
    }
  }
}

curl -X POST http://172.28.32.23:8080/v2/apps -d @./nginx.json -H "Content-type: application/json"
```

mesos 编译安装
https://github.com/apache/mesos
http://mesos.apache.org/gettingstarted/

编译安装，版本1.0.1
http://mesos.apache.org/gettingstarted/

ip 为服务ip
```
cd mesos-1.0.1
nohup ./bin/mesos-master.sh --log_dir=/home/root/mesos/ --ip=172.28.32.23 --work_dir=/home/root/mesos --quorum=1 --zk=zk://172.28.32.180:2181/mesos >> ./mesos-master.log &
nohup ./bin/mesos-agent.sh --containerizers=docker,mesos --master=zk://172.28.32.180:2181/mesos --work_dir=/home/root/mesos >> ./mesos-agent.log &
nohup ./bin/mesos-agent.sh --containerizers=docker,mesos --master=zk://172.28.32.180:2181/mesos --work_dir=/home/root/mesos >> ./mesos-agent.log &

! /bin/bash
IP=localhost:2181
nohup mesos-slave --log_dir=/root/mesos/logs1 --master=zk://${IP}/mesos --containerizers=docker,mesos >>/dev/null 2>&1 &
```

marathon 安装
http://mesosphere.github.io/marathon/docs/
```
cd marathon-1.3.0
nohup ./bin/start --master zk://172.28.32.180:2181/mesos --zk zk://172.28.32.180:2181/marathon >> ./marathon.log &
```

CICD 持续集成

部署jenkins
```
wget http://mirrors.jenkins-ci.org/war-stable/latest/jenkins.war

nohup java -jar jenkins.war --httpPort=8088 >> jenkins.log &

安装插件     Jenkins-> Manage Jenkins-> Manage Plugins-> Available
Mesos Plugin
ElasticBox Jenkins Kubernetes CI/CD Plug-in
```

配置jenkins 注册mesos frameworks
```
Jenkins-> Manage Jenkins-> Configure System-> Add a new cloud(最下)-> Mesos Cloud

Mesos native library path: /usr/local/lib/libmesos.so
Mesos Master [hostname:port]: 172.28.32.23:5050
On-demand framework registration: No(始终注册到mesos frameworks中)
```

执行jekins 任务（maven）

执行jekins 任务（shell）
http://www.aichengxu.com/view/10924977

触发build（webhook？）
Project-> Configure-> Build Triggers->  Authentication Token: dockercicd
http://172.28.32.23:8088/job/test%20docker%20CICD/build?token=dockercicd

```
docker pull centos
docker tag 980e0e4c79ec 172.28.32.23/public/centos:7.2.1511
docker push 172.28.32.23/public/centos:7.2.1511
docker build -t 172.28.32.23/public/centos_jdk:1.8.0 ./docker_jdk/
docker push 172.28.32.23/public/centos_jdk:1.8.0
```

清理未运行的容器
docker rm $(docker ps -a -f status=exited -q)

部署marathon-lb 实现docker 容器的服务发现以及负载均衡.
需要确保端口没有冲突，以保证marathon-lb 能够正常启动.
docker pull docker.io/mesosphere/marathon-lb

通过marathon 启动marathon-lb
```
{
    "id": "marathon-lb",
    "instances": 1,
    "constraints": [["hostname", "UNIQUE"]],
    "container": {
        "type": "DOCKER",
        "docker": {
            "image": "docker.io/mesosphere/marathon-lb",
            "privileged": true,
            "network": "HOST"
        }
    },
    "healthChecks": [
        {
            "protocol": "HTTP",
            "path": "/_haproxy_health_check",
            "gracePeriodSeconds": 3,
            "intervalSeconds": 10,
            "port": 9090,
            "timeoutSeconds": 10,
            "maxConsecutiveFailures": 3
        }
    ],
    "args": ["sse", "-m","http://172.28.32.23:8080", "--group", "httptables.apis"]
}

curl -i -H 'Content-Type: application/json' 172.28.32.23:8080/v2/apps -d@marathon-lb/marathon-lb.json
```

登入marathon-lb 容器，发现如果和宿主机端口存在冲突，haproxy 服务会启动失败。
```
docker exec -it marathon-lb-container-id /bin/bash
ps -ef | grep marathon-lb

haproxy -p /tmp/haproxy.pid -f /marathon-lb/haproxy.cfg -D -sf 43

查看haproxy 配置文件
cat haproxy.cfg

监控端口查询
http://172.28.32.23:9090/_haproxy_getconfig
```

mesos 单机
cd mesos-1.0.1
nohup ./bin/mesos-master.sh --log_dir=/home/root/mesos/ --ip=172.28.32.23 --work_dir=/home/root/mesos >> ./mesos-master.log &
nohup ./bin/mesos-agent.sh --containerizers=docker,mesos --master=172.28.32.23:5050 --work_dir=/home/root/mesos >> ./mesos-agent.log &
cd marathon-1.3.0
nohup ./bin/start --master 172.28.32.23:5050 --zk zk://172.28.32.180:2181/marathon >> ./marathon.log &

mesos 集群部署：
二进制发行版
https://open.mesosphere.com/downloads/mesos/

需要安装 libevent-devel
yum install libevent-devel

vi /etc/systemd/system/multi-user.target.wants/mesos-master.service 

systemctl start mesos-master

启动mesos-agent 时需要绑定ip agent 需要加上参数 --ip=***

编译安装启动集群
cd mesos-1.0.1
nohup ./bin/mesos-master.sh --log_dir=/home/root/mesos/ --ip=172.28.32.23 --work_dir=/home/root/mesos --quorum=1 --zk=zk://172.28.32.180:2181/mesos >> ./mesos-master.log &
nohup ./bin/mesos-agent.sh --ip=172.28.32.23 --containerizers=docker,mesos --master=zk://172.28.32.180:2181/mesos --work_dir=/home/root/mesos >> ./mesos-agent.log &
nohup ./bin/mesos-agent.sh --ip=172.28.32.181 --containerizers=docker,mesos --master=zk://172.28.32.180:2181/mesos --work_dir=/home/root/mesos >> ./mesos-agent.log &
nohup ./bin/mesos-agent.sh --ip=172.28.32.182 --containerizers=docker,mesos --master=zk://172.28.32.180:2181/mesos --work_dir=/home/root/mesos >> ./mesos-agent.log &
nohup ./bin/mesos-agent.sh --ip=172.28.32.183 --containerizers=docker,mesos --master=zk://172.28.32.180:2181/mesos --work_dir=/home/root/mesos >> ./mesos-agent.log &
nohup ./bin/mesos-agent.sh --ip=172.28.32.184 --containerizers=docker,mesos --master=zk://172.28.32.180:2181/mesos --work_dir=/home/root/mesos >> ./mesos-agent.log &
nohup ./bin/mesos-agent.sh --ip=172.28.32.185 --containerizers=docker,mesos --master=zk://172.28.32.180:2181/mesos --work_dir=/home/root/mesos >> ./mesos-agent.log &

registrator /consul /etcd /confd 服务发现

docker pull gliderlabs/registrator

docker pull consul

docker run -d -p 8500:8500 --name=consul consul agent -server

docker run -d --restart=always \
    --name=registrator \
    --net=host \
    --volume=/var/run/docker.sock:/tmp/docker.sock \
    gliderlabs/registrator:latest \
    -ip 172.28.32.181 \
    consul://172.28.32.181:8500/

curl http://172.28.32.181:8500/v1/catalog/services
curl 172.28.32.181:8500/v1/catalog/service/httptables_api

curl -XPUT \
    172.28.32.23:8500/v1/agent/service/register \
    -d '{
        "ID": "simple_instance_1",
        "Name":"simple",
        "Port": 8000, 
        "tags": ["tag"]
    }'

consul-template
https://releases.hashicorp.com/consul-template/0.16.0/consul-template_0.16.0_linux_amd64.zip

vi ctmpl.json
```
consul = "172.28.32.181:8500"

template {
  source = "./haproxy.ctmpl"
  destination = "./haproxy.cfg"
  command = "systemctl reload haproxy"
}
```

vi /etc/haproxy/haproxy.ctmpl
```
global
    log         127.0.0.1 local2
  
    chroot      /var/lib/haproxy
    pidfile     /var/run/haproxy.pid
    maxconn     4000
    user        haproxy
    group       haproxy
    daemon
  
    # turn on stats unix socket
    stats socket /var/lib/haproxy/stats
defaults
    mode                    http
    log                     global
    option                  httplog
    option                  dontlognull
    option http-server-close
    option forwardfor       except 127.0.0.0/8
    option                  redispatch
    retries                 3
    timeout http-request    10s
    timeout queue           1m
    timeout connect         10s
    timeout client          1m
    timeout server          1m
    timeout http-keep-alive 10s
    timeout check           10s
    maxconn                 3000
  
frontend  main *:80
    acl url_static       path_beg       -i /static /images /javascript /stylesheets
    acl url_static       path_end       -i .jpg .gif .png .css .js
  
    use_backend static          if url_static
    default_backend             app
  
backend static
    balance     roundrobin
    server      static 127.0.0.1:4331 check
  
backend app
    balance     roundrobin
        {{range service "httptables_api"}}
        server {{.Name}} {{.Address}}:{{.Port}}{{end}}
```

consul-template -config ./ctmpl.json > consul-template.out 2>&1 &

向etcd 注册信息
docker run -d --restart=always \
    --name=registrator-etcd \
    --net=host \
    --volume=/var/run/docker.sock:/tmp/docker.sock \
    gliderlabs/registrator:latest \
    -ip 172.28.32.183 \
    etcd://192.168.1.169:2379

查看etcd
http://192.168.1.169:2379/v2/keys/httptables_api

下载confd
wget https://github.com/kelseyhightower/confd/releases/download/v0.11.0/confd-0.11.0-linux-amd64

cd confd/
vi confd.toml
```
[template]
src = "haproxy.cfg.tmpl"
dest = "./haproxy.cfg"
keys = [
    "/httptables_api",
]
reload_cmd = "/etc/init.d/haproxy reload"
```
vi haproxy.cfg.tmpl
```
[myconfig]
{{ with get "/httptables_api"}}
 server {{base .Key}} {{.Value}} check
{{end}}
```

./confd-0.11.0-linux-amd64 -verbose -interval 10 -confdir=./ -onetime -backend etcd -node 192.168.1.169:2379 -node 192.168.1.179:2379 -node 192.168.1.180:2379
注意：
-onetime 表示只执行一次即推出
-confdir 配置的路径conf.d/ 中所有的.toml 文件都会被读取和处理，
默认为/etc/confd/conf.d
confd.toml 中src 会自动搜索templates/ 文件夹，
默认为/etc/confd/templates
配置-confdir=./ 之后需要创建./conf.d 和./templates 文件夹
否则没有按预期处理生成配置文件，而且不报错！

```
curl -XPUT http://192.168.1.169:2379/v2/keys/app/servers/backstabbing_rosalind -d value="192.168.1.22:49156"  
curl -XPUT http://192.168.1.169:2379/v2/keys/app/servers/cocky_morse -d value="192.168.1.22:49158"  
curl -XPUT http://192.168.1.169:2379/v2/keys/app/servers/goofy_goldstine -d value="192.168.1.22:49160"  
curl -XPUT http://192.168.1.169:2379/v2/keys/app/servers/prickly_blackwell -d value="192.168.1.22:49162"
```

